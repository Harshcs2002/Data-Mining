{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. Use Naive bayes, K-nearest, and Decision tree classification algorithms and build classifiers. Divide the data set into training and test set. Compare the accuracy of the different classifiers under the following situations:\n",
        "- ## 5.1 a) Training set = 75% Test set = 25% b) Training set = 66.6% (2/3rd of total), Test set = 33.3% \n",
        "- ## 5.2 Training set is chosen by i) hold out method ii) Random subsampling iii) Cross-Validation. Compare the accuracy of the classifiers obtained.\n",
        "- ## 5.3 Data is scaled to standard format."
      ],
      "metadata": {
        "id": "XjiqVnY3Ik1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split , cross_val_score,KFold,StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "6iHFRsM2IqlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data # features\n",
        "y = iris.target # labels\n",
        "\n",
        "# Spliting the data into Training set = 75% & Test set = 25%\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Splitting the data into Training set = 66.6% (2/3rd of total) & Test set =33.3%\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.33, random_state=0)\n"
      ],
      "metadata": {
        "id": "sjqwrpQCGnvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the models\n",
        "gnb = GaussianNB()\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "dt = DecisionTreeClassifier(max_depth=3)"
      ],
      "metadata": {
        "id": "iLMv2uuKGxig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  5.1 a) Training set = 75% Test set = 25% b) Training set = 66.6% (2/3rd of total), Test set = 33.3%"
      ],
      "metadata": {
        "id": "JoWYEvZhISz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate the models under different situations\n",
        "\n",
        "# 5.1 a) Training set = 75% Test set = 25%\n",
        "gnb.fit(X_train1, y_train1)\n",
        "y_pred1 = gnb.predict(X_test1)\n",
        "print(\"Naive Bayes accuracy for 75% training set: \", accuracy_score(y_test1, y_pred1))\n",
        "\n",
        "knn.fit(X_train1, y_train1)\n",
        "y_pred2 = knn.predict(X_test1)\n",
        "print(\"KNN accuracy for 75% training set: \", accuracy_score(y_test1, y_pred2))\n",
        "\n",
        "dt.fit(X_train1, y_train1)\n",
        "y_pred3 = dt.predict(X_test1)\n",
        "print(\"Decision Tree accuracy for 75% training set: \", accuracy_score(y_test1, y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWc9bfLzHBR8",
        "outputId": "8aabfb29-78d6-46da-be4c-eb730033eb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy for 75% training set:  1.0\n",
            "KNN accuracy for 75% training set:  0.9736842105263158\n",
            "Decision Tree accuracy for 75% training set:  0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 b) Training set = 66.6% (2/3rd of total), Test set =33.3%\n",
        "gnb.fit(X_train2, y_train2)\n",
        "y_pred4 = gnb.predict(X_test2)\n",
        "print(\"Naive Bayes accuracy for 66.6% training set: \", accuracy_score(y_test2, y_pred4))\n",
        "\n",
        "knn.fit(X_train2, y_train2)\n",
        "y_pred5 = knn.predict(X_test2)\n",
        "print(\"KNN accuracy for 66.6% training set: \", accuracy_score(y_test2, y_pred5))\n",
        "\n",
        "dt.fit(X_train2, y_train2)\n",
        "y_pred6 = dt.predict(X_test2)\n",
        "print(\"Decision Tree accuracy for 66.6% training set: \", accuracy_score(y_test2, y_pred6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqYo4x-nH4pF",
        "outputId": "a565a9ce-93b4-42a4-ff99-bb64ce3d2e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy for 66.6% training set:  0.96\n",
            "KNN accuracy for 66.6% training set:  0.98\n",
            "Decision Tree accuracy for 66.6% training set:  0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2  Training set is chosen by i) hold out method ii) Random subsampling iii) Cross-Validation. Compare the accuracy of the classifiers obtained."
      ],
      "metadata": {
        "id": "xwCU6fuZII7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hold out method\n",
        "X_train3 , X_test3 , y_train3 , y_test3 = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "gnb.fit(X_train3, y_train3)\n",
        "y_pred7 = gnb.predict(X_test3)\n",
        "print(\"Naive Bayes accuracy for hold out method: \", accuracy_score(y_test3, y_pred7))\n",
        "\n",
        "knn.fit(X_train3, y_train3)\n",
        "y_pred8 = knn.predict(X_test3)\n",
        "print(\"KNN accuracy for hold out method: \", accuracy_score(y_test3, y_pred8))\n",
        "\n",
        "dt.fit(X_train3, y_train3)\n",
        "y_pred9 = dt.predict(X_test3)\n",
        "print(\"Decision Tree accuracy for hold out method: \", accuracy_score(y_test3, y_pred9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH569CvbJsR-",
        "outputId": "5ed68eea-f669-4c93-a85a-fa3e05335e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy for hold out method:  1.0\n",
            "KNN accuracy for hold out method:  1.0\n",
            "Decision Tree accuracy for hold out method:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random subsampling method\n",
        "\n",
        "sum_gnb = 0\n",
        "sum_knn = 0\n",
        "sum_dt = 0\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=i)\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    sum_gnb += accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    sum_knn += accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    dt.fit(X_train, y_train)\n",
        "    y_pred = dt.predict(X_test)\n",
        "    sum_dt += accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Naive Bayes accuracy for random subsampling method: \", sum_gnb/10)\n",
        "print(\"KNN accuracy for random subsampling method: \", sum_knn/10)\n",
        "print(\"Decision Tree accuracy for random subsampling method: \", sum_dt/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrcIPwm9IBzN",
        "outputId": "e2657ffa-d5e3-43fb-a44b-ccdde0f48c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy for random subsampling method:  0.9473684210526315\n",
            "KNN accuracy for random subsampling method:  0.9631578947368421\n",
            "Decision Tree accuracy for random subsampling method:  0.9526315789473683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross-validation\n",
        "gnb_scores = cross_val_score(gnb, X, y, cv=10)\n",
        "print(\"Naive Bayes accuracy for cross-validation: \", gnb_scores.mean())\n",
        "\n",
        "knn_scores = cross_val_score(knn, X, y, cv=10)\n",
        "print(\"KNN accuracy for cross-validation: \", knn_scores.mean())\n",
        "\n",
        "dt_scores = cross_val_score(dt, X, y, cv=10)\n",
        "print(\"Decision Tree accuracy for cross-validation: \", dt_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WS2U51NJ1uG",
        "outputId": "dd7ff7e6-a55f-47d7-eae0-77e64c073b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy for cross-validation:  0.9533333333333334\n",
            "KNN accuracy for cross-validation:  0.9666666666666668\n",
            "Decision Tree accuracy for cross-validation:  0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Data is scaled to standard format."
      ],
      "metadata": {
        "id": "YLR4uMlKKXiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "x_train4 , x_test4 , y_train4 , y_test4 = train_test_split(X_scaled, y, test_size=0.20, random_state=42)\n",
        "\n",
        "gnb.fit(x_train4, y_train4)\n",
        "y_pred10 = gnb.predict(x_test4)\n",
        "print(\"Naive Bayes accuracy for scaled data: \", accuracy_score(y_test4, y_pred10))\n",
        "\n",
        "knn.fit(x_train4, y_train4)\n",
        "y_pred11 = knn.predict(x_test4)\n",
        "print(\"KNN accuracy for scaled data: \", accuracy_score(y_test4, y_pred11))\n",
        "\n",
        "dt.fit(x_train4, y_train4)\n",
        "y_pred12 = dt.predict(x_test4)\n",
        "print(\"Decision Tree accuracy for scaled data: \", accuracy_score(y_test4, y_pred12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHo_b1nBKbMK",
        "outputId": "41d60567-67f1-4638-9832-5a8cffa48cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy for scaled data:  1.0\n",
            "KNN accuracy for scaled data:  1.0\n",
            "Decision Tree accuracy for scaled data:  1.0\n"
          ]
        }
      ]
    }
  ]
}